{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d935e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f98ec868",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e01a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a253dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8883b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68a16be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 20:14:18,542 - text2image - INFO - DialoGPT loaded\n",
      "2022-07-14 20:14:18,561 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: clips/mfaq\n",
      "/home/admin/ClipModel/lib/python3.8/site-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "2022-07-14 20:14:31,301 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device: cuda\n",
      "2022-07-14 20:14:31,516 - text2image - INFO - Sentence Transformer loaded\n",
      "2022-07-14 20:15:16,180 - text2image - INFO - CLIP loaded\n",
      "2022-07-14 20:15:38,373 - text2image - INFO - CLIP features loaded\n"
     ]
    }
   ],
   "source": [
    "import text2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57e90e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 16\n",
    "num_beams = 4\n",
    "gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "263e89be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = ['Say , Jim , how about going for a few beers after dinner ? ',\n",
    " ' You know that is tempting but is really not good for our fitness . ',\n",
    " ' What do you mean ? It will help us to relax . ',\n",
    " \" Do you really think so ? I don't . It will just make us fat and act silly . Remember last time ? \",\n",
    " \" I guess you are right.But what shall we do ? I don't feel like sitting at home . \",\n",
    " ' I suggest a walk over to the gym where we can play singsong and meet some of our friends . ',\n",
    " \" That's a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them . \",\n",
    " ' Sounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too . ',\n",
    " \" Good.Let ' s go now . \",\n",
    " ' All right . ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77c8c95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2819676bdf247e8969e0d6ffe7824a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, scores = text2image.score_image(dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a75d2063",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_for_caption = img[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baf397bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values = feature_extractor(images=img[5], return_tensors=\"pt\").pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fea0c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values = pixel_values.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57378304",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ids = model.generate(pixel_values, **gen_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac86fc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "preds = [pred.strip() for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71656e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a room that has a lot of equipment in it'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95157fb",
   "metadata": {},
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2e985f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0bb3b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_gpt = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f6daf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gpt = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fd14e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tokenizer_gpt.encode(dialog[0] + tokenizer_gpt.eos_token, return_tensors='pt')\n",
    "for elem in dialog[1:5]:\n",
    "    tokens = tokenizer_gpt.encode(elem + tokenizer_gpt.eos_token, return_tensors='pt')\n",
    "    result = torch.cat([tokens, result], dim=-1)\n",
    "#text = text + preds[0] + tokenizer_gpt.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "81cccf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer_gpt.encode(preds[0] + tokenizer_gpt.eos_token, return_tensors='pt')\n",
    "result = torch.cat([tokens, result], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fbcb7f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   64,  2119,   326,   468,   257,  1256,   286,  5112,   287,   340,\n",
       "         50256,   314,  4724,   345,   389,   826,    13,  1537,   644,  2236,\n",
       "           356,   466,  5633,   314,   836,   470,  1254,   588,  5586,   379,\n",
       "          1363,   764,   220, 50256,  2141,   345,  1107,   892,   523,  5633,\n",
       "           314,   836,   470,   764,   632,   481,   655,   787,   514,  3735,\n",
       "           290,   719, 14397,   764, 11436,   938,   640,  5633,   220, 50256,\n",
       "          1867,   466,   345,  1612,  5633,   632,   481,  1037,   514,   284,\n",
       "          8960,   764,   220, 50256,   921,   760,   326,   318, 29850,   475,\n",
       "           318,  1107,   407,   922,   329,   674, 13547,   764,   220, 50256,\n",
       "         25515,   837,  5395,   837,   703,   546,  1016,   329,   257,  1178,\n",
       "         16800,   706,  8073,  5633,   220, 50256]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5187b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = model_gpt.generate(tokens, max_length=300, pad_token_id=tokenizer_gpt.eos_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "feb0bdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   64,  2119,   326,   468,   257,  1256,   286,  5112,   287,   340,\n",
       "         50256,    40,  1101,   407,  1654,   611,   345,   821,  2726,   837,\n",
       "           475,   314,  1053,  1775,   257,  1256,   286,   661,   910,   326,\n",
       "           764, 50256]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d70efc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DialoGPT: a room that has a lot of equipment in itI'm not sure if you're serious, but I've seen a lot of people say that.\n"
     ]
    }
   ],
   "source": [
    "print(\"DialoGPT: {}\".format(tokenizer_gpt.decode(ans[0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b4812144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> User:Say , Jim , how about going for a few beers after dinner ?\n",
      "DialoGPT: I'm not sure if you're serious or not, but I laughed.\n",
      ">> User:You know that is tempting but is really not good for our fitness \n",
      "DialoGPT: I'm not sure if you're serious or not, but I laughed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [79]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/DialoGPT-medium\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# encode the new user input, add the eos_token and return a tensor in Pytorch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     new_user_input_ids \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m>> User:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# append the new user input tokens to the chat history\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     bot_input_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([chat_history_ids, new_user_input_ids], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m new_user_input_ids\n",
      "File \u001b[0;32m~/ClipModel/lib/python3.8/site-packages/ipykernel/kernelbase.py:1177\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1175\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1176\u001b[0m     )\n\u001b[0;32m-> 1177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ClipModel/lib/python3.8/site-packages/ipykernel/kernelbase.py:1219\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "\n",
    "for step in range(5):\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    # pretty print last ouput tokens from bot\n",
    "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6935e684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fdd828e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4f8cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
